% This part is 50 marks and should not exceed two pages including figures.

\subsection{Introduction \& Background}
% TODO: REFS

When a pipelined CPU comes across a branch instruction, it must normally
block the pipeline until the outcome of the branch is known, so that the
correct instructions are fetched. This however is slow and inefficient -
the earlier parts of the pipeline must sit around idle, while the later
ones figure out which instructions are next.

A simple solution to this would be to guess the outcome of the branch
instruction randomly, and assume the outcome until the assumption is
proven incorrect.
The pipeline would fill up with instructions that have a \(50\%\) chance
of being incorrect, and if they are, the contents of the pipeline
can simply be discarded.
This strategy would negate this `branch penalty' half of the time.

Branch prediction is a better approach.
This technique is used by CPUs to improve their guess as to the outcome of
a branch instruction.
Based on information already available, the CPU must make a decision about
the most likely outcome of an upcoming branch instruction. The decision can
then be used as an assumption to continue filling the pipe with instructions,
hopefully negating the branch penalty more than half of the time.

\subsection{Techniques}

\subsubsection{Bimodal Predictor}
% TODO: REFS

A bimodal predictor is very simple.
Each branch instruction is associated with a two bit counter.
Whenever that particular branch is taken, the counter is incremented,
and whenever it is not taken, the counter is decremented.
The counter does not overflow.
The predictor predicts that a branch will be taken if its counter
is \(10\) or \(11\), and it predicts that a branch will not be taken
if its counter is \(00\) or \(01\).~\cite{Mcfarling1993}

\subsubsection{TAGE Predictor}
% Refs:
%    \cite{Michaud2005} ppm-like-tag-based-predictor.pdf
%    \cite{Seznec2006}  a-case-for-tage.pdf
%    \cite{Seznec2007}  the-l-tage-branch-predictor.pdf
%
% All three are from the same two authors. The first introduces a
% similar predictor, the second introduces TAGE, and in the third,
% they collaborate and make a cute paper together :)

The TAGE predictor, or the \textbf{Ta}gged \textbf{Ge}ometric history
length branch predictor is a more advanced technique for branch
prediction.

This predictor relies on the assumption that if the same sequence of
branches happens twice, then the result of the next branch will often
be the same in both instances.
Furthermore, this predictor relies on the assumption that the longer
the length of matching past history, the higher
the probability of matching future branches.~\cite{Seznec2006}

A series of tagged history predictors are used, each using a geometrically
increasing history length - i.e. of the form
\(L_i = \left\lceil \alpha^{i-1} \cdot L_0 \right\rceil\).
If any of the predictors recognise the current branch history,
then the prediction with the longest history is used.
Otherwise, a simpler `base' predictor is used, for example a Bimodal
predictor.~\cite{Seznec2007,Michaud2005}

A TAGE branch predictor is provided by \texttt{gem5}'s \texttt{TAGE}
branch predictor. % ToDO: find out implementation details and write

\subsubsection{Perceptron Predictor}

% Refs:
%   \cite{Jimenez2001} This paper presents the idea of perceptrons in general
%   \cite{Jimenez2014} This paper fleshes it out to multiperspective+tage
%
% Neural network
% Global shift register
% Simple to implement

Another approach to predicting branches is to try and use a
neural network to learn and predict whether or not a branch will
be taken.
The simplest, and therefore easiest neural network to implement
efficiently in hardware is a perceptron.
This neural network simply makes a prediction from the weighted
sum of a set of predictors. i.e. for predictors \(\{ x_1, \ldots , x_n \}\),
and learned weights \(\{ a_1, \ldots , a_n \}\), a prediction, \(\hat{y}\) could
be calculated as shown in Equation~\ref{eq:perceptron}.

\begin{equation}
    \hat{y} = \sum_{i=1}^{n} \left( a_i \cdot x_i \right)
    \label{eq:perceptron}
\end{equation}

This neural network can be applied to branch prediction by interpreting
\(\hat{y} > 0\) as meaning a branch is likely, and \(\hat{y} < 0\) as meaning
a branch is unlikely.
Furthermore, a rough and very efficient form of gradient
descent can be applied to the network, by incrementing all weights whose predictors
have signs matching the actual value of \(y\), and decrementing all weights which
do not.
A set of weights can be learned separately for each branch
instruction.~\cite{Jimenez2001}

In the simplest perceptron branch predictors, the predictor values of \(x_i\)
are a global shift register of previous branch results, where \(x_i = +1\) would
mean that the \(i\)th most recent branch was taken, and \(x_i = -1\) would
mean that the \(i\)th most recent branch was not taken.

More complex perceptron predictors, feed the perceptron many more
factors. For example a local shift register of branch outcomes for the specific
branch that is being predicted, previous branch addresses, and counters for
how many times a branch has been repeated.
Such predictors may be termed
Multi-perspective perceptron branch predictors, as they examine multiple
perspectives of the current situation to conclude whether or not a branch
is likely.~\cite{Jimenez2014}

\texttt{gem5} provides both the \texttt{MultiperspectivePerceptron8KB}
and \texttt{MultiperspectivePerceptron64KB} branch predictor types.
 % ToDO: find out implementation details and write


\subsection{Simulation}
\begin{figure}[b!]%
\hfill%
\begin{subfigure}{.4\textwidth}
    \centering
    \includestandalone[width=\textwidth]{graphs/partd-cpi}
    \caption{CPI}
    \label{fig:partd-cpi}
\end{subfigure}%
\hfill%
\begin{subfigure}{.4\textwidth}
    \centering
    \includestandalone[width=\textwidth]{graphs/partd-mispredict}
    \caption{Misprediction rate (\%)}
    \label{fig:partd-mispredict}
\end{subfigure}%
\hfill\null%
\caption{A comparison of performance factors for CPUs with different branch predictors.}
\label{fig:partd-factors}
\end{figure}

For this part of the coursework, the \texttt{gem5} simulator was invoked with the
command shown in Listing \ref{partD-cmd},
for both benchmark commands, on both CPU architectures, with the branch
predictor types \texttt{BiModeBP}, \texttt{TAGE},
\texttt{MultiperspectivePerceptron8KB},
and~\texttt{MultiperspectivePerceptron64KB}.


\begin{lstlisting}[
    label=partD-cmd,
    language=beef,
    caption={The command used to invoke the \texttt{gem5} simulation for part D.}
]
.../gem5.opt .../se.py --bp-type=${bp} --cpu-type=DerivO3CPU --caches --l1d_size=16KB --l1i_size=16KB -c ${cmd} -o ${args}
\end{lstlisting}

\subsection{Results}

Some of the results of the simulations are shown in Figure~\ref{fig:partd-factors}.

Comparing Figures~\ref{fig:partd-mispredict} and \ref{fig:partd-cpi}, CPI and
misprediction rates appear to be clearly correlated. This is what we would expect, as
mispredicting a branch would incur a performance penalty. Branch misprediction rate is
therefore a useful performance metric for a branch predictor.

The changes in branch predictor have very little effect on the CRC32
benchmark when compared to the SUSAN benchmark. This is not due to there being more
branches in the SUSAN benchmark. In fact, \(20.0\%\) of ARM and \(18.5\%\) of X86
instructions were branches for CRC32, against only \(11.2\%\) and \(7.4\%\) for SUSAN.
The main difference between the benchmarks is the predictability of the branches.
The CRC algorithm
consists of a tight loop, iterating through the data character by character,
making the branches very easy to predict, whereas the SUSAN algorithm has
many branches that depend on the data itself, which are far harder to predict.

A static branch predictor, where the branch instructions in the main loop of the CRC32
algorithm are assumed to always be taken would likely perform just as well as any of
the predictors being tested.
The ease of predicting the branches causes every predictor except the 64KB perceptron
to make very few mispredictions on the CRC benchmark, explaining the small size of
differences in performance.
The poor performance of the 64KB perceptron
on the CRC benchmark in Figure~\ref{fig:partd-mispredict}, could be explained
by a large neural net being prone to over-fitting for such a simple task.~\cite{Engin2004,Culpepper2005}

In terms of branch mispredictions, the best performing predictor was the 8KB TAGE
predictor. This makes sense, as the design is much more sophisticated than a simple
bimodal predictor.
A reason for the poor performance of the perceptrons may be because they need time to learn
how to accurately predict the benchmarks. Perhaps if we were to use an even longer test,
or to measure the misprediction rates only after an initial learning period, they would
perform significantly better. The low misprediction rates of the 8KB TAGE show that it
is possible to almost perfectly predict the branches for these benchmarks, so an error-filled
period of initial learning will be significantly detrimental to any other branch predictor
in comparison.
Perhaps in a situation where a CPU is running for a far longer time, with a more
widely spanning codebase than these benchmarks, the perceptron could
eventually pick out more subtly correlated features with branches, and eventually
have the lowest misprediction rates, but in this case, a TAGE branch predictor
appears to be the most performant.



% OBSERVATIONS
%  Only SUSAN really changes, not CRC
%  arm crc has  133168908 branches/665779085 insts = 20.001%
%  arm susan has 27942399 branches/249571591 insts = 11.196%
%  x86 crc has  133165845 branches/719021518 insts = 18.520%
%  x86 susan has 27114764 branches/364696464 insts =  7.435%
%
%  CRC has far more branches but mispredict rate is almost always 0%
%  hence no improvement.
%
%  CPI and branch mispredict rates match up, which is good!
%
%  No consistent difference between X86 and ARM.
%
%  64KB perceptron is terrible (overfitting??)
%
% TODO: Look at all the actual implementations and see what is inside


