% This part is 40 marks and should not exceed two pages including figures.

\subsection{Introduction \& Background}

Cache is a necessary part of a processor as it allows frequently used data to be stored
close to the processor where it is much quicker to access.

There are multiple levels of cache, commonly seen from levels 1 to 3.
As the level decreases, the cache size gets smaller but its access time becomes faster.
Excluding registers, level 1 cache is the fastest type of memory and in order to maximize
its speed it is placed inside the processor.
Access time for level 1 cache is in the order of 1-2 clock cycles compared to 100 cycles
to access main memory, the place where currently running programs and all the working
data are stored.

Cache can be split into two types, one for storing instructions of the programs the
processor is running, and one for storing the data the processor is manipulating.
These are respectively named Instruction Cache and Data Cache.

In this experiment, we are analysing the effect of increasing the size of both the
Level 1 Instruction Cache and the Level 1 Data Cache.

\subsection{Method}

The \texttt{gem5} simulation was performed for both the ARM and X86 architectures, for
each of the SUSAN and CRC32 benchmark programs.
For each of these combinations, the l1i\_size (instruction cache size) argument was 
iterated through the set \{2kB, 4kB, 8kB, 16kB, 32kB\} and the l1d\_size (data cache size) 
argument was iterated through the set \{2kB, 4kB, 8kB, 16kB, 32kB, 64kB\}.

\begin{lstlisting}[
    language=beef,
    caption={The command used to invoke the \texttt{gem5} simulation for the SUSAN benchmark.}
]
./build/${architecture}/gem5.opt configs/example/se.py --l1d_size=${l1d} --l1i_size=${l1i} --caches --cpu-type=TimingSimpleCPU -c ../mibench/automotive/susan/susan -o "../mibench/automotive/susan/input_large.pgm output_large.smoothing.pgm -s"
\end{lstlisting}

\begin{lstlisting}[
    language=beef,
    caption={The command used to invoke the \texttt{gem5} simulation for the CRC32 benchmark.}
]
./build/${architecture}/gem5.opt configs/example/se.py --l1d_size=${l1d} --l1i_size=${l1i} --caches --cpu-type=TimingSimpleCPU -c ../mibench/telecomm/CRC32/crc -o "../mibench/telecomm/adpcm/data/large.pcm > output_large.txt"
\end{lstlisting}



This produced a dataset of 120 individual simulations with varying data and instruction
cache sizes.
Key values from the results of each of these simulations, such as number of cycles, 
number of instructions, and miss rate were scraped from the output files and assembled 
in table format.

\subsection{Results \& Analysis}

\subsubsection{Data Cache Size}

From the results, it can be seen that increasing the size of the data cache from 2kB to 
4kB greatly improves the performance of the processor, however the gains rapidly 
decrease for larger sizes of data cache.

The X86 chip running the CRC32 benchmark program sees the greatest improvements in 
performance.

\begin{figure}[H]
    \centering
    \includestandalone[width=.6\textwidth]{graphs/parta-l1d}
    \caption{A comparison of the CPI results for different sizes of data cache}
    \label{fig:parta-l1d}
\end{figure}

\subsubsection{Instruction Cache Size}

From the results, it can be seen that increasing the size of the instruction cache 
slightly improves the performance of the processor.

\begin{figure}[H]
    \centering
    \includestandalone[width=.6\textwidth]{graphs/parta-l1i}
    \caption{A comparison of the CPI results for different sizes of instruction cache}
    \label{fig:parta-l1i}
\end{figure}

The X86 programs see more improvement than the ARM programs.
This may be due to the fact that the size of the X86 binaries are around twice that of 
the ARM binaries, so there is a need for more instruction cache.
