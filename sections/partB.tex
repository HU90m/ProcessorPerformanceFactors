% This part is 30 marks and should not exceed two pages including figures.

\subsection{Introduction \& Background}
\begin{wrapfigure}{R}{.5\textwidth}
    \centering
    \includestandalone[width=.4\textwidth]{graphs/partb-assoc}
    \caption{A graph of cache misses against cache associativity}
    \label{fig:partb-assoc}
\end{wrapfigure}%
\subsubsection{Cache Line Size}

The most basic form of cache associativity is Direct Mapped Cache, corresponding to an
associativity of 1.
In this case, each address in main memory is mapped to only one location in cache.
Because each data address doesn't have a choice in what cache cell it can be placed,
it can lead to situations where cache is overwritten when there are still spaces in
the cache that aren't being used.

A solution to this problem is to use set-associative cache.
In this system, a memory address is given a number of cache blocks it can be written to.
This number of cache blocks is called the associativity of the cache.

When loading a series of data from main memory to the cache, it may be the case that
multiple of these data requests are for data which exist consecutively in memory.
This situation revels an opportunity to speed up the program by not only loading
the data you are requesting into the cache, but also at the same time preemptively loading
the data located before and after the address of the data that the program just requested.

This can save time as it means some data will be preemptively loaded into the cache right
before it is needed.
However, it can also decrease performance if the program doesn't use data in the order that
it exists in memory, because time is wasted loading data into the cache which will go unused
by the processor.

\subsection{Method}

The \texttt{gem5} simulation was performed for only the X86 architecture, for each of the
SUSAN and CRC32 benchmark programs.
In every simulation, the size of the instruction cache was set to 8kB and the size
of the data cache was set to 16kB.
For each of these, the \texttt{l1d\_assoc} (data cache association) argument was iterated
through the set \{1, 2, 4, 8, 16, 32, 64\} and the \texttt{cacheline\_size} (cache line size) argument
was iterated through the set \{16kB, 32kB, 64kB, 128kB\}.

\begin{lstlisting}[
    language=beef,
    caption={The command used to invoke the \texttt{gem5} simulation for the SUSAN benchmark.}
]
./build/${architecture}/gem5.opt configs/example/se.py --l1d_size=16kB --l1i_size=8kB --caches --l1d_assoc=${assoc} --cacheline_size=${cacheline} --cpu-type=TimingSimpleCPU -c ../mibench/automotive/susan/susan -o "../mibench/automotive/susan/input_large.pgm output_large.smoothing.pgm -s"
\end{lstlisting}

\begin{lstlisting}[
    language=beef,
    caption={The command used to invoke the \texttt{gem5} simulation for the CRC32 benchmark.}
]
./build/${architecture}/gem5.opt configs/example/se.py --l1d_size=16kB --l1i_size=8kB --caches --l1d_assoc=${assoc} --cacheline_size=${cacheline} --cpu-type=TimingSimpleCPU -c ../mibench/telecomm/CRC32/crc -o "../mibench/telecomm/adpcm/data/large.pcm > output_large.txt"
\end{lstlisting}

This produced a dataset of 56 individual simulations with varying cache line sizes and
associativities.
Key values from the results of each of these simulations, such as number of cycles,
number of instructions, and miss rate were scraped from the output files and assembled 
in table format.

\subsection{Results \& Analysis}

\subsubsection{Cache Associativity}

From the results, shown in Figure~\ref{fig:partb-assoc},
it can be seen that increasing the associativity of the cache from 
1 to 2 greatly improves the miss rate of the processor. After that, increasing the 
associativity any further has little effect on the overall performance.

It can be seen that increasing the associativity can nearly completely eliminate
cache misses when running the CRC32 benchmark, however the SUSAN benchmark sees a near
constant 0.02\% miss rate from an associativity of 2 onwards.

The associativity of the cache makes a large difference on the effects of an increased cache
line size.
The cache miss rates for varies cache line sizes with different cache associativities are
shown in Figure~\ref{fig:partb-cacheline}.

For an associativity of 1, shown in Figure~\ref{fig:partb-2d1},
the cache miss rate tends to increase as the cache line size
does, whereas for larger associativities, shown in Figure~\ref{fig:partb-2d8},
as cache line size increases, cache miss rate
decreases.
This result is expected because with an associativity of 1 and a large cache line size,
there is an increased chance of the processor overwriting actively used data in cache.
With a larger associativity however, this effect is negated as the cache is able to choose
from many different cache blocks to write the data in.

As can be seen in Figures~\ref{fig:partb-2d-crc} and~\ref{fig:partb-2d-susan},
for the SUSAN benchmark, cache line size contributes far more significantly to the cache
miss rate than cache associativity. This makes sense, as although the SUSAN benchmark
does not access memory in the very sequential manner of the CRC algorithm, it will process
pixels in similar areas of the image at once.
So if it needs
a particular byte, it is very likely to need nearby ones, so fetching them all at once could
significantly improve performance.

Overall, a lower cache miss rate can be achieved on the CRC32 benchmark than the SUSAN
benchmark. This could be explained by the fact that the CRC32 benchmark accesses its data
in a very sequential
manner, word by word, which could easily be cached ready, whereas the SUSAN algorithm accesses
memory in a far less predictable manner, and since the cache is of a limited size, it will
never have all of the required data ready for the SUSAN benchmark.

\begin{figure}[H]%
\centering%
\hfill%
\begin{subfigure}{.4\textwidth}
    \centering
    \includestandalone[width=\textwidth]{graphs/partb-2d1}
    \caption{Changing cacheline size with Associativity=1}
    \label{fig:partb-2d1}
\end{subfigure}%
\hfill%
\begin{subfigure}{.4\textwidth}
    \centering
    \includestandalone[width=\textwidth]{graphs/partb-2d8}
    \caption{Changing cacheline size with Associativity=8}
    \label{fig:partb-2d8}
\end{subfigure}%
\hfill\null%
\vskip\baselineskip\hfill%
\begin{subfigure}{.4\textwidth}
    \centering
    \includestandalone[width=\textwidth]{graphs/partb-2d-susan}
    \caption{Changing cacheline size and associativity for the SUSAN benchmark}
    \label{fig:partb-2d-susan}
\end{subfigure}%
\hfill%
\begin{subfigure}{.4\textwidth}
    \centering
    \includestandalone[width=\textwidth]{graphs/partb-2d-crc}
    \caption{Changing cacheline size and associativity for the CRC benchmark}
    \label{fig:partb-2d-crc}
\end{subfigure}%
\hfill\null%
\caption{The effects of changing cacheline size and associativity on cache miss rate}
\label{fig:partb-cacheline}
\end{figure}
